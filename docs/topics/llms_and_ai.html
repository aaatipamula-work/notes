<!DOCTYPE html>
    <html>
    <head>
    <meta charset="UTF-8">
    <title>LLM's and AI</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/styles/nord.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/Microsoft/vscode/extensions/markdown-language-features/media/markdown.css">
    <style>
      body {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe WPC', 'Segoe UI', system-ui, 'Ubuntu', 'Droid Sans', sans-serif;
        font-size: 14px;
        line-height: 1.6;
        background-color: #3B4252;
        color: #D8DEE9;
      }

      h1 {
        color: #8FBCBB;
      }

      h2 {
        color: #88C0D0;
      }

      h3 {
        color: #81A1C1;
      }

      h4 {
        color: #5E81AC;
      }

      strong {
        color: #BF616A;
      }

      em {
        color: #EBCB8B;
      }

      strong em {
        color: #D08770;
      }

      a {
        color: #A3BE8C;
      }

      .task-list-item {
        list-style-type: none;
      }

      .task-list-item-checkbox {
        margin-left: -20px;
        vertical-align: middle;
        pointer-events: none;
      }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.7.0/highlight.min.js"></script>
    <script>hljs.highlightAll()</script>
  </head>
    <body class="vscode-body vscode-light">
        <!--title: LLMs and AI -->
<h1 id="table-of-contents-">Table of Contents <!-- omit in toc --></h1>
<p><code>Important Sections are Italicized!</code></p>
<ul>
<li><a href="#reference">Reference</a>
<ul>
<li><a href="#openai-notes"><em>OpenAI Notes</em></a></li>
<li><a href="#langchain-notes"><em>LangChain Notes</em></a></li>
<li><a href="#llamaindex-notes">LlamaIndex Notes</a>
<ul>
<li><a href="#query-vs-chat-engines">Query v.s. Chat Engines</a></li>
</ul>
</li>
<li><a href="#database-connection-strings"><em>Database Connection Strings</em></a>
<ul>
<li><a href="#documentation-links">Documentation Links</a></li>
<li><a href="#examples">Examples</a></li>
</ul>
</li>
<li><a href="#environment-setup">Environment Setup</a>
<ul>
<li><a href="#formatting">Formatting</a></li>
<li><a href="#access">Access</a></li>
</ul>
</li>
<li><a href="#code-snippets">Code Snippets</a></li>
<li><a href="#questions-to-ask">Questions to Ask</a></li>
<li><a href="#thoughts">Thoughts</a>
<ul>
<li><a href="#ideas">Ideas</a></li>
<li><a href="#problems">Problems</a></li>
<li><a href="#watch">Watch</a></li>
<li><a href="#solved">Solved</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#implementations">Implementations</a>
<ul>
<li><a href="#sql-chain"><em>SQL Chain</em></a>
<ul>
<li><a href="#conceptual">Conceptual</a></li>
<li><a href="#code-examples">Code Examples</a></li>
</ul>
</li>
<li><a href="#sql-agent"><em>SQL Agent</em></a>
<ul>
<li><a href="#conceptual-1">Conceptual</a></li>
<li><a href="#code-examples-1">Code Examples</a></li>
</ul>
</li>
<li><a href="#llamaindex-implementation">LlamaIndex Implementation</a>
<ul>
<li><a href="#conceptual-2">Conceptual</a></li>
<li><a href="#code-examples-2">Code Examples</a></li>
</ul>
</li>
<li><a href="#schema-indexing">Schema Indexing</a>
<ul>
<li><a href="#conceptual-3">Conceptual</a></li>
<li><a href="#process">Process</a></li>
<li><a href="#changes-to-the-standard-implementation">Changes to the Standard Implementation</a></li>
<li><a href="#improvements-to-be-made">Improvements to be Made</a></li>
</ul>
</li>
<li><a href="#view-schema-prompt-injection">View Schema Prompt Injection</a>
<ul>
<li><a href="#conceptual-4">Conceptual</a></li>
</ul>
</li>
<li><a href="#prompt-injection">Prompt Injection</a></li>
</ul>
</li>
</ul>
<h1 id="reference">Reference</h1>
<h2 id="openai-notes"><em>OpenAI Notes</em></h2>
<p><a href="https://platform.openai.com/docs/introduction">General Docs</a></p>
<p>Most of the following is links to reading and resources that could be helpful when looking into OpenAI and GPT:</p>
<ul>
<li><a href="https://github.com/openai/openai-cookbook">OpenAI Cookbook</a>
<ul>
<li>A Github repo of useful links and resources.</li>
</ul>
</li>
<li><a href="https://platform.openai.com/docs/models">OpenAI Models</a>
<ul>
<li>A list of all the models OpenAI currently has for use.</li>
</ul>
</li>
<li><a href="https://platform.openai.com/docs/guides/gpt-best-practices">Best Practices for GPT</a>
<ul>
<li>Guidelines from OpenAI on how to instruct models.</li>
</ul>
</li>
<li><a href="https://platform.openai.com/docs/guides/safety-best-practices">Best Practices for Safety</a></li>
<li><a href="https://platform.openai.com/docs/guides/production-best-practices">Best Practices for Production</a></li>
</ul>
<h2 id="langchain-notes"><em>LangChain Notes</em></h2>
<p><a href="https://python.langchain.com/docs/get_started">Python Docs</a></p>
<p><a href="https://github.com/hwchase17/langchain">Github</a></p>
<p>A fairly popular python/js framework to use for LLM AI prompting and management.</p>
<p>The following are some of the python docs LangChain has on useful topics to get familiar with some how the framework and how LLM generative AI works in general:</p>
<ul>
<li><a href="https://python.langchain.com/docs/get_started/quickstart#environment-setup">Environment Setup</a>
<ul>
<li>Setting up your python program.</li>
<li>Also refer to my <a href="#environment-setup">notes</a></li>
</ul>
</li>
<li><a href="https://python.langchain.com/docs/modules/model_io/prompts/">Prompts</a>
<ul>
<li>Good to understand how this works first.</li>
</ul>
</li>
<li><a href="https://python.langchain.com/docs/modules/model_io/models/">LLM v.s. Chat Models</a></li>
<li><a href="https://python.langchain.com/docs/modules/data_connection/">Overview of Data Connection</a>
<ul>
<li>Connecting SQL databases, processing documents etc.</li>
</ul>
</li>
<li><a href="https://python.langchain.com/docs/modules/chains/">What are Chains?</a></li>
<li><a href="https://python.langchain.com/docs/modules/agents/">What are Agents?</a></li>
<li><a href="https://python.langchain.com/docs/modules/memory/">Adding Memory</a>
<ul>
<li>For both Agents and Chains.</li>
</ul>
</li>
<li><a href="https://python.langchain.com/docs/modules/callbacks/">Callbacks</a>
<ul>
<li>Hooking into the function calls being made, useful for logging and looking at an agent or chains's &quot;thought process&quot;</li>
</ul>
</li>
</ul>
<p>Most of these are not very long, just conceptual overviews with a few examples written in python. I found them to be a good starting point to understand how something works and then diving deeper from there.</p>
<h2 id="llamaindex-notes">LlamaIndex Notes</h2>
<p><a href="https://gpt-index.readthedocs.io/en/latest/index.html">Python Docs</a></p>
<p><a href="https://github.com/jerryjliu/llama_index">Github</a></p>
<p>This is a framework that improves upon LangChain and makes it easier to link data.</p>
<p>From what I've tried its fairly slow, and doesn't seem to offer much in the way of use flexibility. I may come back to this but for now I'm focusing on LangChain.</p>
<p>Pros:</p>
<ul>
<li>It may provide more accurate queries.</li>
</ul>
<p>Cons:</p>
<ul>
<li>Less control over implementation.</li>
</ul>
<h3 id="query-vs-chat-engines">Query v.s. Chat Engines</h3>
<ul>
<li>Query engines are solely focused on answering the question, they do not retain context and are similar in nature to an SQL Chain</li>
<li>Chat engines are more conversational, but slightly more prone to injecting irrelevant context into answers.</li>
</ul>
<h2 id="database-connection-strings"><em>Database Connection Strings</em></h2>
<h3 id="documentation-links">Documentation Links</h3>
<ul>
<li><a href="https://docs.sqlalchemy.org/en/20/dialects/mssql.html#module-sqlalchemy.dialects.mssql.pyodbc">MSSQL Connections</a>
<ul>
<li>Additional Info</li>
</ul>
</li>
<li><a href="https://docs.sqlalchemy.org/en/20/tutorial/engine.html">Engine Connections</a>
<ul>
<li>Use if using a different connection other than MSSQL</li>
</ul>
</li>
</ul>
<h3 id="examples">Examples</h3>
<p><a href="#langchain-notes">LangChain</a> uses <a href="https://www.sqlalchemy.org/">SQLAlchemy</a> (A Python Object Relational Mapping library) for SQL database connection</p>
<p>The following code works if you are implicitly authenticating with the user you are logged in as on a Windows machine for MSSQL Server using LangChain's SQLDatabase wrapper:</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> SQLDatabase

server = <span class="hljs-string">&quot;hostname_or_ip&quot;</span>
database = <span class="hljs-string">&quot;databasename&quot;</span>

db = SQLDatabase.from_uri(
    <span class="hljs-string">&quot;mssql+pyodbc://&quot;</span>+server+<span class="hljs-string">&quot;/&quot;</span>+database+<span class="hljs-string">&quot;?driver=ODBC+Driver+17+for+SQL+Server&quot;</span>
)
</code></pre>
<p>If you are authenticating with SQL credentials instead use the following:</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> SQLDatabase

server = <span class="hljs-string">&quot;hostname_or_ip&quot;</span>
database = <span class="hljs-string">&quot;databasename&quot;</span>
username = <span class="hljs-string">&quot;usernamehere&quot;</span>
password = <span class="hljs-string">&quot;passwordhere&quot;</span>

db = SQLDatabase.from_uri(
    <span class="hljs-string">f&quot;mssql+pyodbc://<span class="hljs-subst">{username}</span>:<span class="hljs-subst">{password}</span>@<span class="hljs-subst">{server}</span>/<span class="hljs-subst">{database}</span>?driver=ODBC+Driver+17+for+SQL+Server&quot;</span>
)
</code></pre>
<h2 id="environment-setup">Environment Setup</h2>
<h3 id="formatting">Formatting</h3>
<p>Environment Variables are formatted in all capitalized letters and with underscores such as the following:</p>
<pre><code class="language-sh">API_TOKEN_XYZ=<span class="hljs-string">&quot;key_here&quot;</span>
</code></pre>
<h3 id="access">Access</h3>
<p>This is relatively simple in Python, refer to the following:</p>
<pre><code class="language-python"><span class="hljs-keyword">import</span> os

ENV_VARIABLE = os.environ.get(<span class="hljs-string">&quot;API_TOKEN_XYZ&quot;</span>)
</code></pre>
<p>There are 3 ways I would suggest you set <a href="https://en.wikipedia.org/wiki/Environment_variable">Environment Variables</a>
- dotenv
- Command line
- Hard code</p>
<p>It is standard to keep the formatting of constant variables and loaded environment variables in the same <a href="#formatting">formatting</a> as environment variables.</p>
<p><strong>dotenv</strong></p>
<p>I would suggest this method as its usually pretty versatile and a standard in Python</p>
<p>Simply download the dotenv library with:</p>
<pre><code class="language-shell">pip install python-dotenv --upgrade
</code></pre>
<p>and use it in your code by putting the following at the top of the file you're running:</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv

load_dotenv(<span class="hljs-string">&quot;/path/to/.env&quot;</span>)
</code></pre>
<p>It is customary to name your Environment Variables file <code>.env</code>. Refer to <a href="#formatting">formatting</a> for how to structure the file and <a href="#access">access</a> on how to grab the values of the env variables.</p>
<p><strong>Command line</strong></p>
<p>Before running your program run the following command in your command line:</p>
<pre><code class="language-shell">export API_TOKEN_XYZ=&quot;token_here&quot;
</code></pre>
<p><em>NOTE</em>: Make sure not to put any spaces on either side of the <code>=</code> character, this will lead to errors.</p>
<p>Refer to <a href="#access">access</a> on how to grab the values of the env variables.</p>
<p><strong>Hard Code</strong></p>
<p>I would not suggest you use this method, but if you would like to use the following code:</p>
<pre><code class="language-python"><span class="hljs-keyword">import</span> os

os.environ[<span class="hljs-string">&quot;API_TOKEN_XYZ&quot;</span>] = <span class="hljs-string">&quot;token_here&quot;</span>
</code></pre>
<p>Refer to <a href="#access">access</a> on how to grab the values of the env variables.</p>
<h2 id="code-snippets">Code Snippets</h2>
<p>This is a useful function to interact with an Agent or Chain in the command line:</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> SQLDatabaseChain
<span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> AgentExecutor

<span class="hljs-keyword">def</span> <span class="hljs-title function_">mainEventLoop</span>(<span class="hljs-params">aiObject: AgentExecutor | SQLDatabaseChain</span>):
    <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:
        <span class="hljs-keyword">try</span>: 
            userInput = <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;User: &quot;</span>)
            <span class="hljs-keyword">if</span> userInput.lower() <span class="hljs-keyword">in</span> [<span class="hljs-string">&quot;exit&quot;</span>, <span class="hljs-string">&quot;close&quot;</span>]:
                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Exiting...&quot;</span>)
                exit(<span class="hljs-number">0</span>)
            ai_response = aiObject.run(userInput)
            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;AI: <span class="hljs-subst">{ai_response}</span>&quot;</span>)

        <span class="hljs-keyword">except</span> KeyboardInterrupt:
            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Exiting...&quot;</span>)
            exit(<span class="hljs-number">0</span>)
        
        <span class="hljs-keyword">except</span> InvalidRequestError <span class="hljs-keyword">as</span> err:
            <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;<span class="hljs-subst">{err._message}</span>&quot;</span>)
</code></pre>
<h2 id="questions-to-ask">Questions to Ask</h2>
<ul>
<li>How many tickets were created in the month of may?</li>
<li>Group those tickets by status.</li>
</ul>
<h2 id="thoughts">Thoughts</h2>
<h3 id="ideas">Ideas</h3>
<ul>
<li>If an API exists and uses the OpenAPI standard, we can create a program to parse and create queries for the API similar to the examples above.</li>
<li>Try using Views
<ul>
<li><strong>Implementation</strong>: Remove any tools to query the schema and tables, just inject into the prompt. Guide through prompting.</li>
</ul>
</li>
<li><em>Get rid of the ID Columns, we only use those to refrence specific things and it would muddy the prompt fed to the LLM</em></li>
<li><em>Hard Code in a WHERE col = 'val' to prevent peeking into other users data</em></li>
</ul>
<h3 id="problems">Problems</h3>
<ul>
<li>Too many tokens throws an error
<ul>
<li><strong>Idea</strong>: <code>try except</code> block.</li>
<li><strong>Idea</strong>: Token limits</li>
</ul>
</li>
<li><em>Missing some input keys: {'input'}</em>
<ul>
<li>Not sure how to solve this one tbh</li>
</ul>
</li>
<li>Understanding
<ul>
<li><img src="../../pictures/understanding.png" alt="context"></li>
<li><strong>Idea</strong>: Change the <a href="#openai-notes">model</a></li>
<li>Not sure how to solve this yet</li>
</ul>
</li>
<li>Repetitition
<ul>
<li><img src="../../pictures/repetition.png" alt="context"></li>
<li><strong>Idea</strong>: Change the <a href="#openai-notes">model</a></li>
</ul>
</li>
</ul>
<h3 id="watch">Watch</h3>
<ul>
<li>Doesn't pick up correct Status:
<img src="../../pictures/wrongstatus.png" alt="context">
<ul>
<li><strong>Idea</strong>: Create a tool
<ul>
<li>This is working somewhat, the only problem is that the llm is putting more than one word as an input.</li>
<li>Create a tool to list all the statuses.</li>
</ul>
</li>
<li><em>Potential Solution</em>: Prompting
<ul>
<li><img src="../../pictures/sdcasestatus.png" alt="context"></li>
<li>This works for specific things but I would have to add a line for every status which would compound really fast.</li>
<li>Found a better way that just lists all the possible values.</li>
</ul>
<blockquote>
<p>Values in the sdCaseStatusDesc column can only be the following: Approved, Waiting For Triage, Parking Lot, On Hold, In Requirements, In Development Queue, Researching, Being Worked, Waiting for Customer, Pending Additional Information, Ready for QA, In UAT, Waiting to be Released, Resolved, To Be Scheduled, Pending Approval, In QA</p>
</blockquote>
</li>
<li><em>Potential Solution</em>: Added the following code to list out possible values in columns<pre><code class="language-python"><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>
<span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> SQLDatabase

<span class="hljs-keyword">class</span> <span class="hljs-title class_">SQLDatabaseExt</span>(<span class="hljs-title class_ inherited__">SQLDatabase</span>):

<span class="hljs-keyword">def</span> <span class="hljs-title function_">col_values</span>(<span class="hljs-params">self, columns: <span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], table: <span class="hljs-built_in">str</span></span>):
    fin_str = <span class="hljs-string">&quot;&quot;</span>
    <span class="hljs-keyword">for</span> col <span class="hljs-keyword">in</span> columns:
        query = <span class="hljs-string">f&quot;SELECT <span class="hljs-subst">{col}</span> from <span class="hljs-subst">{table}</span> GROUP BY <span class="hljs-subst">{col}</span>&quot;</span>
        fin_str += <span class="hljs-string">f&quot;Values in the <span class="hljs-subst">{col}</span> column can only be one of the following\n<span class="hljs-subst">{self.run_no_throw(query)}</span>\n\n&quot;</span>
</code></pre>
</li>
</ul>
</li>
<li>Not using count where applicable
<ul>
<li><em>Potential Solution</em>: Add the following to the prompt:
<blockquote>
<p>Use aggregate functions such as COUNT and GROUP BY when asked about quantities.</p>
</blockquote>
</li>
</ul>
</li>
<li>Uses name from context when not applicable
<img src="../../pictures/context.png" alt="context">
<ul>
<li><strong>Idea</strong>: Prompt this out.</li>
<li><em>Potential Solution</em>: Add the following line to the prompt
<blockquote>
<p>Disregard previous conversation history when not related to the question.</p>
</blockquote>
</li>
</ul>
</li>
<li>User Names:
<ul>
<li><em>Potential Solution</em>: Create a tool to grab user names and ids when question prompts for a user<pre><code class="language-python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">QueryUserNames</span>(<span class="hljs-title class_ inherited__">BaseTool</span>):
    <span class="hljs-string">&quot;&quot;&quot;Tool for getting the correct user name.&quot;&quot;&quot;</span>

    db: SQLDatabase

    name = <span class="hljs-string">&quot;grab_user_name&quot;</span>
    description = <span class="hljs-string">&quot;&quot;&quot;
    Input to this tool is the name of a user provided by a question. This will output the UserId and the full UserName of the inputted user if there is no relevant user found nothing will be given back. 
    &quot;&quot;&quot;</span>

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">_run</span>(<span class="hljs-params">
        self,
        query: <span class="hljs-built_in">str</span>,
        run_manager: <span class="hljs-type">Optional</span>[CallbackManagerForToolRun] = <span class="hljs-literal">None</span>,
    </span>) -&gt; <span class="hljs-built_in">str</span>:
        <span class="hljs-string">&quot;&quot;&quot;Execute the query, return the results or an error message.&quot;&quot;&quot;</span>
        <span class="hljs-keyword">return</span> self.db.run_no_throw(<span class="hljs-string">f&quot;SELECT TOP 1 * FROM AI_UserIDXNameView WHERE Username LIKE &#x27;%<span class="hljs-subst">{query}</span>%&#x27;&quot;</span>)

    <span class="hljs-keyword">async</span> <span class="hljs-keyword">def</span> <span class="hljs-title function_">_arun</span>(<span class="hljs-params">
        self,
        query: <span class="hljs-built_in">str</span>,
        run_manager: <span class="hljs-type">Optional</span>[AsyncCallbackManagerForToolRun] = <span class="hljs-literal">None</span>,
    </span>) -&gt; <span class="hljs-built_in">str</span>:
        <span class="hljs-keyword">raise</span> NotImplementedError(<span class="hljs-string">&quot;QuerySqlDbTool does not support async&quot;</span>)
</code></pre>
</li>
<li><strong>Idea</strong>: Use First and Last Name columns, prompt to search using both columns</li>
<li><strong>Idea</strong> <em><strong>Deprecated</strong></em>: Indexing User Names and Injecting them into the prompt</li>
</ul>
</li>
</ul>
<h3 id="solved">Solved</h3>
<ul>
<li>Question Semantics:
<ul>
<li><em>Solved</em>: Should be solved by <a href="#ideas">Views</a> but bugs may pop up.</li>
</ul>
</li>
<li>Understanding Table Joins (Relationships between Tables)
<ul>
<li><em>Solved</em>: Using <a href="#ideas">Views</a> to flatten out tables.</li>
</ul>
</li>
<li>Doesn't specify a year
<ul>
<li><em>Solved</em>: Inserted a line in the prompt to specify year</li>
</ul>
<blockquote>
<p>Always use the year {year} unless a year is specified in a question.</p>
</blockquote>
</li>
<li>Memory
<ul>
<li><em>Solved</em>: Added <code>ConversationWindowBufferMemory</code> to the Agent Executor</li>
</ul>
</li>
</ul>
<h1 id="implementations">Implementations</h1>
<p>Things I've tried to connect an SQL database with AI</p>
<h2 id="sql-chain"><em>SQL Chain</em></h2>
<p><a href="https://python.langchain.com/docs/modules/chains/popular/sqlite">Python Docs</a></p>
<h3 id="conceptual">Conceptual</h3>
<ul>
<li>Similar to how ChatGPT works, you give the LLM a directive and when it gets a question it crafts a query to use, extracts information and answers the question.</li>
</ul>
<p>Pros:</p>
<ul>
<li>Using an sql chain could be beneficial as you can choose if data is exposed to the api.</li>
<li>Easier to tweak behavior.</li>
</ul>
<p>Cons:</p>
<ul>
<li>However sql chains not very effective when crafting complex queries.</li>
<li>Can only really answer simple questions about very simple schemas</li>
</ul>
<h3 id="code-examples">Code Examples</h3>
<p>This is an example of a chain that uses a custom prompt:</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv
<span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> OpenAI, SQLDatabase, SQLDatabaseChain, PromptTemplate

load_dotenv(<span class="hljs-string">&quot;/path/to/.env&quot;</span>)

server = <span class="hljs-string">&quot;hostname_or_ip&quot;</span>
database = <span class="hljs-string">&quot;databasename&quot;</span>

llm = OpenAI(temperature=<span class="hljs-number">0</span>, verbose=<span class="hljs-literal">True</span>)
db = SQLDatabase.from_uri(
    <span class="hljs-string">&quot;mssql+pyodbc://&quot;</span>+server+<span class="hljs-string">&quot;/&quot;</span>+database+<span class="hljs-string">&quot;?driver=ODBC+Driver+17+for+SQL+Server&quot;</span>,
)

dbtemplate = <span class="hljs-string">&quot;&quot;&quot;
Given an input question, first create a syntactically correct {dialect} query to run, then look at the results of the query and return the answer.
Use the following format:

Question: &quot;Question here&quot;
SQLQuery: &quot;SQL Query to run&quot;
SQLResult: &quot;Result of the SQLQuery&quot;
Answer: &quot;Final answer here&quot;

Only use the following tables:
characters
organization

Question: {input} &quot;&quot;&quot;</span>

dbprompt = PromptTemplate(
    input_variables=[<span class="hljs-string">&quot;input&quot;</span>, <span class="hljs-string">&quot;dialect&quot;</span>],
    template=dbtemplate
)

db_chain = SQLDatabaseChain.from_llm(
    llm=llm,
    db=db, 
    prompt=dbprompt, 
    verbose=<span class="hljs-literal">True</span>, 
    <span class="hljs-comment"># Check if the query that the Chain comes up with is valid</span>
    use_query_checker=<span class="hljs-literal">True</span>, 
)
</code></pre>
<p>It can be run with the following:</p>
<pre><code class="language-python">db_chain.run(<span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Question: &quot;</span>))
</code></pre>
<p>Refer to <a href="#code-snippets">code snippets</a> for a simple command line interface.</p>
<h2 id="sql-agent"><em>SQL Agent</em></h2>
<p><a href="https://python.langchain.com/docs/modules/agents/toolkits/sql_database">Python Docs</a></p>
<h3 id="conceptual-1">Conceptual</h3>
<ul>
<li>Based on the sql chain, it uses multiple queries to the API to break the larger question into smaller ones it will answer to produce a final answer.</li>
</ul>
<p>Pros:</p>
<ul>
<li>This will usually execute the sql queries fairly well returning a concise answer.</li>
<li>Much better with complex schemas and sometimes picks up on context in vague questions.</li>
</ul>
<p>Cons:</p>
<ul>
<li>Not very conversational and only give direct answers.</li>
<li>Its slightly experimental as of right now</li>
<li>Less control over how the bot behaves.</li>
</ul>
<p>Other Considerations:</p>
<ul>
<li>Could fine tune prompt and instruction set for the sql agent by making a custom agent.</li>
</ul>
<h3 id="code-examples-1">Code Examples</h3>
<p>This is much simpler as most of the setup is relegated to the langchain framework but it is highly customizable if wanted.</p>
<pre><code class="language-python"><span class="hljs-keyword">from</span> dotenv <span class="hljs-keyword">import</span> load_dotenv
<span class="hljs-keyword">from</span> langchain <span class="hljs-keyword">import</span> OpenAI, SQLDatabase
<span class="hljs-keyword">from</span> langchain.agents <span class="hljs-keyword">import</span> create_sql_agent
<span class="hljs-keyword">from</span> langchain.agents.agent_toolkits <span class="hljs-keyword">import</span> SQLDatabaseToolkit

load_dotenv(<span class="hljs-string">&quot;/path/to/.env&quot;</span>)

server = <span class="hljs-string">&quot;hostname_or_ip&quot;</span>
database = <span class="hljs-string">&quot;databasename&quot;</span>

llm = OpenAI(temperature=<span class="hljs-number">0</span>, verbose=<span class="hljs-literal">True</span>)
db = SQLDatabase.from_uri(
    <span class="hljs-string">&quot;mssql+pyodbc://&quot;</span>+server+<span class="hljs-string">&quot;/&quot;</span>+database+<span class="hljs-string">&quot;?driver=ODBC+Driver+17+for+SQL+Server&quot;</span>,
)
toolkit = SQLDatabaseToolkit(db=db, llm=llm)

agent_executor = create_sql_agent(
    llm=llm,
    toolkit=toolkit,
    verbose=<span class="hljs-literal">True</span>
)
</code></pre>
<p>It can be run with the following:</p>
<pre><code class="language-python">agent_executor.run(<span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;Question: &quot;</span>))
</code></pre>
<p>Refer to <a href="#code-snippets">code snippets</a> for a simple command line interface.</p>
<h2 id="llamaindex-implementation">LlamaIndex Implementation</h2>
<h3 id="conceptual-2">Conceptual</h3>
<ul>
<li>Index the schema of the database and use that to procure the correct tables</li>
</ul>
<h3 id="code-examples-2">Code Examples</h3>
<p>The following is a custom class I made that generates the SQL Database's index and creates a query or chat engine.</p>
<pre><code class="language-python"><span class="hljs-comment"># Typing imports</span>
<span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">Union</span>, <span class="hljs-type">Optional</span>, <span class="hljs-type">List</span>, <span class="hljs-type">Any</span>
<span class="hljs-keyword">from</span> llama_index.response.schema <span class="hljs-keyword">import</span> RESPONSE_TYPE
<span class="hljs-keyword">from</span> llama_index.indices.query.schema <span class="hljs-keyword">import</span> QueryType
<span class="hljs-keyword">from</span> llama_index.indices.query.base <span class="hljs-keyword">import</span> BaseQueryEngine
<span class="hljs-keyword">from</span> llama_index.chat_engine.types <span class="hljs-keyword">import</span> BaseChatEngine


<span class="hljs-keyword">import</span> os
<span class="hljs-keyword">from</span> llama_index <span class="hljs-keyword">import</span> SQLStructStoreIndex, SQLDatabase, VectorStoreIndex, StorageContext, load_index_from_storage
<span class="hljs-keyword">from</span> llama_index.indices.struct_store <span class="hljs-keyword">import</span> SQLContextContainerBuilder
<span class="hljs-keyword">from</span> sqlalchemy <span class="hljs-keyword">import</span> create_engine, URL

<span class="hljs-comment"># Wrapper around the process of creating and SQL Query Engine</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">SQLAIEngineGenerator</span>:
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">
            self, 
            url: <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, URL], 
            query_string: QueryType, 
            tables: <span class="hljs-type">Optional</span>[<span class="hljs-type">Union</span>[<span class="hljs-type">List</span>[<span class="hljs-built_in">str</span>], <span class="hljs-literal">None</span>]] = <span class="hljs-literal">None</span>,
            debug: <span class="hljs-built_in">bool</span> = <span class="hljs-literal">False</span>,
            **kwargs
        </span>) -&gt; <span class="hljs-literal">None</span>:
        <span class="hljs-string">&quot;&quot;&quot;
        A wrapper around the setup of a query or chat engine. The class simply creates an index for a query and chat engine to be initiated. Class methods are then used to generate the Chat engine and the Query engine.

        Args:
        url: URL connection string for the SQLAlchemey engine. Refer to SQLAlchemy docs for more information.
        tables: Tables to include within the database.
        query_string: An example question to ask the engine to identify the context.
        debug: add logging for debugging
        &quot;&quot;&quot;</span>

        <span class="hljs-keyword">if</span> debug:
            <span class="hljs-comment"># Lazy load</span>
            <span class="hljs-keyword">import</span> logging

            logging.basicConfig(filename=<span class="hljs-string">&quot;index.log&quot;</span>, filemode=<span class="hljs-string">&quot;w&quot;</span>, level=logging.DEBUG)

        <span class="hljs-comment"># Error if no OpenAI key detected</span>
        <span class="hljs-keyword">if</span> os.environ.get(<span class="hljs-string">&quot;OPENAI_API_KEY&quot;</span>)  <span class="hljs-keyword">is</span> <span class="hljs-literal">None</span>:
            <span class="hljs-keyword">raise</span> KeyError(<span class="hljs-string">&quot;No OpenAi API key found.&quot;</span>)

        <span class="hljs-comment"># Define database and create and store schema</span>
        engine = create_engine(url)
        database = SQLDatabase(engine, include_tables=tables)
        context_builder = SQLContextContainerBuilder(database)

        db_schema_index = context_builder.derive_index_from_context(
            VectorStoreIndex, 
            store_index=<span class="hljs-literal">True</span>,
            **kwargs
        )

        context_builder.query_index_for_context(
            db_schema_index,
            query_string,
            store_context_str=<span class="hljs-literal">True</span>
        )

        context_container = context_builder.build_context_container()

        self.index = SQLStructStoreIndex(
            [],
            sql_database=database,
            sql_context_container=context_container,
            **kwargs
        )

    <span class="hljs-keyword">def</span> <span class="hljs-title function_">create_chat_engine</span>(<span class="hljs-params">self</span>) -&gt; BaseChatEngine:
        <span class="hljs-keyword">return</span> self.index.as_chat_engine()
    
    <span class="hljs-keyword">def</span> <span class="hljs-title function_">create_query_engine</span>(<span class="hljs-params">self</span>) -&gt; BaseQueryEngine:
       <span class="hljs-keyword">return</span> self.index.as_query_engine()
</code></pre>
<h2 id="schema-indexing">Schema Indexing</h2>
<p>A somewhat of what <a href="#llamaindex-implementation">LlamaIndex</a> does but with some improvements to flexibility</p>
<h3 id="conceptual-3">Conceptual</h3>
<ul>
<li>Creates an index of the databases schema to use for reference.</li>
<li>At query time it identifies the relevant tables and injects it into the prompt</li>
</ul>
<h3 id="process">Process</h3>
<ul>
<li>Generate an Index of the Database Schema
<ul>
<li>This can be done from a file (and updated if needed)</li>
<li>This can also be directly done from the database</li>
</ul>
</li>
<li>Append context
<ul>
<li>This can be automatically generated by the llm or manually written out by a user</li>
</ul>
</li>
<li>Generate documents
<ul>
<li>Each document contains a table, its schema, and context for the table</li>
</ul>
</li>
<li>Feed documents to a vector store database</li>
<li>Initiate an agent with a retrieval tool that queries the vector store database for the correct tables</li>
</ul>
<h3 id="changes-to-the-standard-implementation">Changes to the Standard Implementation</h3>
<ul>
<li>Uses an index of the Schema <em>with context</em> to produce the correct tables.</li>
<li>Hard Coded the use of DROP, UPDATE, DELETE, INSERT, LIMIT as unusable.</li>
<li>Custom Prompting to encourage correct actions and &quot;thoughts&quot;</li>
</ul>
<h3 id="improvements-to-be-made">Improvements to be Made</h3>
<ul>
<li>Use a more robust vector store DB</li>
<li>Changes to Prompting</li>
<li>Concurrency (asynchronus function calls)</li>
</ul>
<h2 id="view-schema-prompt-injection">View Schema Prompt Injection</h2>
<h3 id="conceptual-4">Conceptual</h3>
<ul>
<li>Simply create a view with all the applicable data and inject the schema of the view into the prompt</li>
</ul>
<h2 id="prompt-injection">Prompt Injection</h2>
<p><em><strong>Have not tried this yet</strong></em></p>
<p>A system where a user sends a prompt to our program and we modify that prompt with data stored from a database and then send it to the OpenAI API.</p>
<p><a href="https://github.com/promptslab/Promptify">Promptify</a> is a NLP (Natural Language Processing) library that may be useful for this idea.</p>
<p>Pros:</p>
<ul>
<li>Minimal use of the gpt api</li>
<li>We get to choose what information to send to the api</li>
</ul>
<p>Cons:</p>
<ul>
<li>Would have to create a system to figure out what information to include and send to the API.</li>
<li>May have to create an entirely different system to find the relevant information to include.</li>
</ul>

        
        
    </body>
    </html>